{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface-hub\n",
    "!pip install datasets\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub in /home/minne/.local/lib/python3.8/site-packages (0.2.1)\n",
      "Requirement already satisfied: requests in /home/minne/.local/lib/python3.8/site-packages (from huggingface-hub) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/minne/.local/lib/python3.8/site-packages (from huggingface-hub) (3.10.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from huggingface-hub) (5.3.1)\n",
      "Requirement already satisfied: tqdm in /home/minne/.local/lib/python3.8/site-packages (from huggingface-hub) (4.62.3)\n",
      "Requirement already satisfied: filelock in /home/minne/.local/lib/python3.8/site-packages (from huggingface-hub) (3.4.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/minne/.local/lib/python3.8/site-packages (from huggingface-hub) (21.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests->huggingface-hub) (3.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/minne/.local/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub) (2.4.7)\n",
      "Requirement already satisfied: datasets in /home/minne/.local/lib/python3.8/site-packages (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from datasets) (1.17.4)\n",
      "Requirement already satisfied: xxhash in /home/minne/.local/lib/python3.8/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /home/minne/.local/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/minne/.local/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: pandas in /home/minne/.local/lib/python3.8/site-packages (from datasets) (1.3.0rc1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/minne/.local/lib/python3.8/site-packages (from datasets) (0.2.1)\n",
      "Requirement already satisfied: packaging in /home/minne/.local/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/minne/.local/lib/python3.8/site-packages (from datasets) (2021.11.1)\n",
      "Requirement already satisfied: dill in /home/minne/.local/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: aiohttp in /home/minne/.local/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/minne/.local/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /home/minne/.local/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/minne/.local/lib/python3.8/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->datasets) (2019.3)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/minne/.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.0)\n",
      "Requirement already satisfied: filelock in /home/minne/.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/minne/.local/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (19.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/minne/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/minne/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/minne/.local/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.9)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/minne/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/minne/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/minne/.local/lib/python3.8/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2019.11.28)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (1.25.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.14.0)\n",
      "Requirement already satisfied: nltk in /home/minne/.local/lib/python3.8/site-packages (3.6.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/minne/.local/lib/python3.8/site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /home/minne/.local/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /home/minne/.local/lib/python3.8/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/minne/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/minne/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import wordnet\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset daily_dialog (/home/minne/.cache/huggingface/datasets/daily_dialog/default/1.0.0/c03444008e9508b8b76f1f6793742d37d5e5f83364f8d573c2747bff435ea55c)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('daily_dialog',split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dialog', 'act', 'emotion'],\n",
       "    num_rows: 11118\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Say , Jim , how about going for a few beers after dinner ? ',\n",
       "       ' You know that is tempting but is really not good for our fitness . ',\n",
       "       ' What do you mean ? It will help us to relax . ',\n",
       "       \" Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ? \",\n",
       "       \" I guess you are right.But what shall we do ? I don't feel like sitting at home . \",\n",
       "       ' I suggest a walk over to the gym where we can play singsong and meet some of our friends . ',\n",
       "       \" That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \",\n",
       "       ' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . ',\n",
       "       \" Good.Let ' s go now . \", ' All right . '], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['dialog'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp_w = stopwords.words('english')\n",
    "def rm_stop_words(tokens):\n",
    "    clean = []\n",
    "    for w in tokens:\n",
    "        if w not in stp_w:\n",
    "            clean.append(w)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalization(text_list, wo_stop_words = True):\n",
    "    list_lower = [re.sub(r'[^a-z0-9\\s]',' ',text.lower()) for text in text_list] #removes punctuation, converts all letters to lowercase\n",
    "    tokenized_list = [nltk.word_tokenize(sent) for sent in list_lower]\n",
    "    if wo_stop_words:\n",
    "        for i, tokens in enumerate(tokenized_list):\n",
    "            tokenized_list[i] = rm_stop_words(tokens)\n",
    "    lema = wordnet.WordNetLemmatizer()\n",
    "    for i, tokens in enumerate(tokenized_list): \n",
    "        tags_list = pos_tag(tokens, tagset = None)\n",
    "        lema_words = []\n",
    "        for token, pos_token in tags_list:\n",
    "            if pos_token.startswith('V'): #verb\n",
    "                pos_val = 'v'\n",
    "            elif pos_token.startswith('J'): #adj\n",
    "                pos_val = 'a'\n",
    "            elif pos_token.startswith('R'): #adv\n",
    "                pos_val = 'r'\n",
    "            else:\n",
    "                pos_val = 'n' #noun\n",
    "            lema_token = lema.lemmatize(token, pos_val)\n",
    "            lema_words.append(lema_token)\n",
    "        tokenized_list[i] = ' '.join(lema_words)  \n",
    "    return tokenized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say jim go beer dinner'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_normalization(df_train['dialog'][0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning of some sentances lost, if I remove stop words, so I will keep all words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should I remove numbers from the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['dialog_prepros'] = df_train['dialog'].apply(text_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['say jim go beer dinner',\n",
       " 'know tempt really good fitness',\n",
       " 'mean help u relax',\n",
       " 'really think make u fat act silly remember last time',\n",
       " 'guess right shall feel like sit home',\n",
       " 'suggest walk gym play singsong meet friend',\n",
       " 'good idea hear mary sally often go play pingpong perhaps make foursome',\n",
       " 'sound great willing could ask go dance u excellent exercise fun',\n",
       " 'good let go',\n",
       " 'right']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['dialog_prepros'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['dialog_prepros_w_stop'] = df_train['dialog'].apply(lambda x:text_normalization(x, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['say jim how about go for a few beer after dinner',\n",
       " 'you know that be tempt but be really not good for our fitness',\n",
       " 'what do you mean it will help u to relax',\n",
       " 'do you really think so i don t it will just make u fat and act silly remember last time',\n",
       " 'i guess you be right but what shall we do i don t feel like sit at home',\n",
       " 'i suggest a walk over to the gym where we can play singsong and meet some of our friend',\n",
       " 'that s a good idea i hear mary and sally often go there to play pingpong perhaps we can make a foursome with them',\n",
       " 'sound great to me if they be willing we could ask them to go dance with u that be excellent exercise and fun too',\n",
       " 'good let s go now',\n",
       " 'all right']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['dialog_prepros_w_stop'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_excel('DailyDialog_lemmatized.xlsx', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['say jim how about go for a few beer after dinner',\n",
       " 'you know that be tempt but be really not good for our fitness',\n",
       " 'what do you mean it will help u to relax',\n",
       " 'do you really think so i don t it will just make u fat and act silly remember last time',\n",
       " 'i guess you be right but what shall we do i don t feel like sit at home',\n",
       " 'i suggest a walk over to the gym where we can play singsong and meet some of our friend',\n",
       " 'that s a good idea i hear mary and sally often go there to play pingpong perhaps we can make a foursome with them',\n",
       " 'sound great to me if they be willing we could ask them to go dance with u that be excellent exercise and fun too',\n",
       " 'good let s go now',\n",
       " 'all right']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['dialog_prepros_w_stop'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_transformed = tfidf.fit(df_train['dialog_prepros_w_stop'].apply(lambda x:', '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_idf_transformed = df_train['dialog_prepros_w_stop'].apply(lambda x: list(tfidf.transform(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [  (0, 10719)\\t0.2555721735467611\\n  (0, 6870)...\n",
       "1        [  (0, 13768)\\t0.14918103724167428\\n  (0, 1300...\n",
       "2        [  (0, 13768)\\t0.12281680582247476\\n  (0, 1357...\n",
       "3        [  (0, 13768)\\t0.2915987198626801\\n  (0, 10427...\n",
       "4        [  (0, 12363)\\t0.24305856600691172\\n  (0, 1120...\n",
       "                               ...                        \n",
       "11113    [  (0, 13772)\\t0.17021991242860476\\n  (0, 1105...\n",
       "11114    [  (0, 13768)\\t0.13729790117857787\\n  (0, 1082...\n",
       "11115    [  (0, 12867)\\t0.4559664189024807\\n  (0, 12387...\n",
       "11116    [  (0, 13768)\\t0.1888655140677948\\n  (0, 11184...\n",
       "11117    [  (0, 12327)\\t0.21255588081950755\\n  (0, 9400...\n",
       "Name: tf_idf_transformed, Length: 11118, dtype: object"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset.with_transform()\n",
    "df_train['tf_idf_transformed']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
